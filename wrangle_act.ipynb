{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 4,
        "hidden": false,
        "row": 0,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "# Project: Wrangling and Analyze Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    "import json \n",
    "from timeit import default_timer as timer\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Gathering\n",
    "In the cell below, gather **all** three pieces of data for this project and load them in the notebook. **Note:** the methods required to gather each data are different.\n",
    "1. Directly download the WeRateDogs Twitter archive data (twitter_archive_enhanced.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "# Download twitter-archive-enhanced file directly from web and add to project.\n",
    "# Import file contents into pandas dataframe called twitter_archive\n",
    "\n",
    "twitter_archive = pd.read_csv('twitter-archive-enhanced.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Use the Requests library to download the tweet image prediction (image_predictions.tsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "335079"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import image_predictions.tsv using requests library\n",
    "\n",
    "url = 'https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv'\n",
    "r = requests.get(url, allow_redirects=True)\n",
    "\n",
    "# Save to local tsv file\n",
    "open('image-predictions.tsv', 'wb').write(r.content)\n",
    "\n",
    "# https://www.tutorialspoint.com/downloading-files-from-web-using-python"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Use the Tweepy library to query additional data via the Twitter API (tweet_json.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note to evaluator - Not using the Twitter API since it does not work without having a paid developer account.\n",
    "# Using the backup option of importing tweet_json.txt file directly from Udacity\n",
    "\n",
    "# DO NOT RUN THIS CODE - adding failsafe so that this block will not run unless exec_api_code is set to True\n",
    "exec_api_code = False\n",
    "\n",
    "if exec_api_code:\n",
    "    # Query Twitter API for each tweet in the Twitter archive and save JSON in a text file\n",
    "    # These are hidden to comply with Twitter's API terms and conditions\n",
    "    consumer_key = 'HIDDEN'\n",
    "    consumer_secret = 'HIDDEN'\n",
    "    access_token = 'HIDDEN'\n",
    "    access_secret = 'HIDDEN'\n",
    "\n",
    "    auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_token, access_secret)\n",
    "\n",
    "    api = tweepy.API(auth, wait_on_rate_limit=True)\n",
    "\n",
    "    # NOTE TO STUDENT WITH MOBILE VERIFICATION ISSUES:\n",
    "    # df_1 is a DataFrame with the twitter_archive_enhanced.csv file. You may have to\n",
    "    # change line 17 to match the name of your DataFrame with twitter_archive_enhanced.csv\n",
    "    # NOTE TO REVIEWER: this student had mobile verification issues so the following\n",
    "    # Twitter API code was sent to this student from a Udacity instructor\n",
    "    # Tweet IDs for which to gather additional data via Twitter's API\n",
    "    tweet_ids = twitter_archive.tweet_id.values\n",
    "    len(tweet_ids)\n",
    "\n",
    "    # Query Twitter's API for JSON data for each tweet ID in the Twitter archive\n",
    "    count = 0\n",
    "    fails_dict = {}\n",
    "    start = timer()\n",
    "    # Save each tweet's returned JSON as a new line in a .txt file\n",
    "    with open('tweet_json.txt', 'w') as outfile:\n",
    "        # This loop will likely take 20-30 minutes to run because of Twitter's rate limit\n",
    "        for tweet_id in tweet_ids:\n",
    "            count += 1\n",
    "            print(str(count) + \": \" + str(tweet_id))\n",
    "            try:\n",
    "                tweet = api.get_status(tweet_id, tweet_mode='extended')\n",
    "                print(\"Success\")\n",
    "                json.dump(tweet._json, outfile)\n",
    "                outfile.write('\\n')\n",
    "            except tweepy.TweepError as e:\n",
    "                print(\"Fail\")\n",
    "                fails_dict[tweet_id] = e\n",
    "                pass\n",
    "    end = timer()\n",
    "    print(end - start)\n",
    "    print(fails_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>id_str</th>\n",
       "      <th>full_text</th>\n",
       "      <th>truncated</th>\n",
       "      <th>display_text_range</th>\n",
       "      <th>entities</th>\n",
       "      <th>extended_entities</th>\n",
       "      <th>source</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>...</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>favorited</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>possibly_sensitive</th>\n",
       "      <th>possibly_sensitive_appealable</th>\n",
       "      <th>lang</th>\n",
       "      <th>retweeted_status</th>\n",
       "      <th>quoted_status_id</th>\n",
       "      <th>quoted_status_id_str</th>\n",
       "      <th>quoted_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tue Aug 01 16:23:56 +0000 2017</td>\n",
       "      <td>892420643555336193</td>\n",
       "      <td>892420643555336193</td>\n",
       "      <td>This is Phineas. He's a mystical boy. Only eve...</td>\n",
       "      <td>False</td>\n",
       "      <td>[0, 85]</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>{'media': [{'id': 892420639486877696, 'id_str'...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>39467</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tue Aug 01 00:17:27 +0000 2017</td>\n",
       "      <td>892177421306343426</td>\n",
       "      <td>892177421306343426</td>\n",
       "      <td>This is Tilly. She's just checking pup on you....</td>\n",
       "      <td>False</td>\n",
       "      <td>[0, 138]</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>{'media': [{'id': 892177413194625024, 'id_str'...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>33819</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mon Jul 31 00:18:03 +0000 2017</td>\n",
       "      <td>891815181378084864</td>\n",
       "      <td>891815181378084864</td>\n",
       "      <td>This is Archie. He is a rare Norwegian Pouncin...</td>\n",
       "      <td>False</td>\n",
       "      <td>[0, 121]</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>{'media': [{'id': 891815175371796480, 'id_str'...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>25461</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sun Jul 30 15:58:51 +0000 2017</td>\n",
       "      <td>891689557279858688</td>\n",
       "      <td>891689557279858688</td>\n",
       "      <td>This is Darla. She commenced a snooze mid meal...</td>\n",
       "      <td>False</td>\n",
       "      <td>[0, 79]</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>{'media': [{'id': 891689552724799489, 'id_str'...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>42908</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sat Jul 29 16:00:24 +0000 2017</td>\n",
       "      <td>891327558926688256</td>\n",
       "      <td>891327558926688256</td>\n",
       "      <td>This is Franklin. He would like you to stop ca...</td>\n",
       "      <td>False</td>\n",
       "      <td>[0, 138]</td>\n",
       "      <td>{'hashtags': [{'text': 'BarkWeek', 'indices': ...</td>\n",
       "      <td>{'media': [{'id': 891327551943041024, 'id_str'...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>41048</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       created_at                  id              id_str  \\\n",
       "0  Tue Aug 01 16:23:56 +0000 2017  892420643555336193  892420643555336193   \n",
       "1  Tue Aug 01 00:17:27 +0000 2017  892177421306343426  892177421306343426   \n",
       "2  Mon Jul 31 00:18:03 +0000 2017  891815181378084864  891815181378084864   \n",
       "3  Sun Jul 30 15:58:51 +0000 2017  891689557279858688  891689557279858688   \n",
       "4  Sat Jul 29 16:00:24 +0000 2017  891327558926688256  891327558926688256   \n",
       "\n",
       "                                           full_text  truncated  \\\n",
       "0  This is Phineas. He's a mystical boy. Only eve...      False   \n",
       "1  This is Tilly. She's just checking pup on you....      False   \n",
       "2  This is Archie. He is a rare Norwegian Pouncin...      False   \n",
       "3  This is Darla. She commenced a snooze mid meal...      False   \n",
       "4  This is Franklin. He would like you to stop ca...      False   \n",
       "\n",
       "  display_text_range                                           entities  \\\n",
       "0            [0, 85]  {'hashtags': [], 'symbols': [], 'user_mentions...   \n",
       "1           [0, 138]  {'hashtags': [], 'symbols': [], 'user_mentions...   \n",
       "2           [0, 121]  {'hashtags': [], 'symbols': [], 'user_mentions...   \n",
       "3            [0, 79]  {'hashtags': [], 'symbols': [], 'user_mentions...   \n",
       "4           [0, 138]  {'hashtags': [{'text': 'BarkWeek', 'indices': ...   \n",
       "\n",
       "                                   extended_entities  \\\n",
       "0  {'media': [{'id': 892420639486877696, 'id_str'...   \n",
       "1  {'media': [{'id': 892177413194625024, 'id_str'...   \n",
       "2  {'media': [{'id': 891815175371796480, 'id_str'...   \n",
       "3  {'media': [{'id': 891689552724799489, 'id_str'...   \n",
       "4  {'media': [{'id': 891327551943041024, 'id_str'...   \n",
       "\n",
       "                                              source  in_reply_to_status_id  \\\n",
       "0  <a href=\"http://twitter.com/download/iphone\" r...                    NaN   \n",
       "1  <a href=\"http://twitter.com/download/iphone\" r...                    NaN   \n",
       "2  <a href=\"http://twitter.com/download/iphone\" r...                    NaN   \n",
       "3  <a href=\"http://twitter.com/download/iphone\" r...                    NaN   \n",
       "4  <a href=\"http://twitter.com/download/iphone\" r...                    NaN   \n",
       "\n",
       "   ... favorite_count  favorited retweeted possibly_sensitive  \\\n",
       "0  ...          39467      False     False              False   \n",
       "1  ...          33819      False     False              False   \n",
       "2  ...          25461      False     False              False   \n",
       "3  ...          42908      False     False              False   \n",
       "4  ...          41048      False     False              False   \n",
       "\n",
       "  possibly_sensitive_appealable lang retweeted_status quoted_status_id  \\\n",
       "0                         False   en              NaN              NaN   \n",
       "1                         False   en              NaN              NaN   \n",
       "2                         False   en              NaN              NaN   \n",
       "3                         False   en              NaN              NaN   \n",
       "4                         False   en              NaN              NaN   \n",
       "\n",
       "  quoted_status_id_str  quoted_status  \n",
       "0                  NaN            NaN  \n",
       "1                  NaN            NaN  \n",
       "2                  NaN            NaN  \n",
       "3                  NaN            NaN  \n",
       "4                  NaN            NaN  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data from the tweet_json.txt file, line by line, into Pandas dataframe\n",
    "with open('tweet_json.txt') as f:\n",
    "    tweet_details = pd.DataFrame(json.loads(line) for line in f)\n",
    "\n",
    "tweet_details.head()\n",
    "\n",
    "# https://stackoverflow.com/questions/20037430/reading-multiple-json-records-into-a-pandas-dataframe"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 4,
        "hidden": false,
        "row": 28,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "## Assessing Data\n",
    "In this section, detect and document at least **eight (8) quality issues and two (2) tidiness issue**. You must use **both** visual assessment\n",
    "programmatic assessement to assess the data.\n",
    "\n",
    "**Note:** pay attention to the following key points when you access the data.\n",
    "\n",
    "* You only want original ratings (no retweets) that have images. Though there are 5000+ tweets in the dataset, not all are dog ratings and some are retweets.\n",
    "* Assessing and cleaning the entire dataset completely would require a lot of time, and is not necessary to practice and demonstrate your skills in data wrangling. Therefore, the requirements of this project are only to assess and clean at least 8 quality issues and at least 2 tidiness issues in this dataset.\n",
    "* The fact that the rating numerators are greater than the denominators does not need to be cleaned. This [unique rating system](http://knowyourmeme.com/memes/theyre-good-dogs-brent) is a big part of the popularity of WeRateDogs.\n",
    "* You do not need to gather the tweets beyond August 1st, 2017. You can, but note that you won't be able to gather the image predictions for these tweets since you don't have access to the algorithm used.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality issues\n",
    "1.\n",
    "\n",
    "2.\n",
    "\n",
    "3.\n",
    "\n",
    "4.\n",
    "\n",
    "5.\n",
    "\n",
    "6.\n",
    "\n",
    "7.\n",
    "\n",
    "8."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 7,
        "hidden": false,
        "row": 40,
        "width": 12
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "### Tidiness issues\n",
    "1.\n",
    "\n",
    "2."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 4,
        "hidden": false,
        "row": 32,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "## Cleaning Data\n",
    "In this section, clean **all** of the issues you documented while assessing. \n",
    "\n",
    "**Note:** Make a copy of the original data before cleaning. Cleaning includes merging individual pieces of data according to the rules of [tidy data](https://cran.r-project.org/web/packages/tidyr/vignettes/tidy-data.html). The result should be a high-quality and tidy master pandas DataFrame (or DataFrames, if appropriate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make copies of original pieces of data\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #1:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #2:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "source": [
    "#### Define"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing Data\n",
    "Save gathered, assessed, and cleaned master dataset to a CSV file named \"twitter_archive_master.csv\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing and Visualizing Data\n",
    "In this section, analyze and visualize your wrangled data. You must produce at least **three (3) insights and one (1) visualization.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insights:\n",
    "1.\n",
    "\n",
    "2.\n",
    "\n",
    "3."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "Downloading files using requests library: https://www.tutorialspoint.com/downloading-files-from-web-using-python\n",
    "Read Json file line by line into dataframe: https://stackoverflow.com/questions/20037430/reading-multiple-json-records-into-a-pandas-dataframe\n"
   ]
  }
 ],
 "metadata": {
  "extensions": {
   "jupyter_dashboards": {
    "activeView": "report_default",
    "version": 1,
    "views": {
     "grid_default": {
      "cellMargin": 10,
      "defaultCellHeight": 20,
      "maxColumns": 12,
      "name": "grid",
      "type": "grid"
     },
     "report_default": {
      "name": "report",
      "type": "report"
     }
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
